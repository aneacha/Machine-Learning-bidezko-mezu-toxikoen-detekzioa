{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZdD3AicgNd4Gm3e1BzW3M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Google Drivetik kargatu**"],"metadata":{"id":"sfrf1NHAFsDF"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rq2yDso2nvzT","executionInfo":{"status":"ok","timestamp":1718819908624,"user_tz":-120,"elapsed":19937,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}},"outputId":"9cf14c14-0a60-44ee-abda-f4737a5c774b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","dir = \"/content/drive/MyDrive/TFG/\""]},{"cell_type":"code","source":["import pickle # Fitxategia irekitzeko erabiltzen da.\n","\n","with open(dir + \"data.bin\",mode=\"rb\") as f:\n","  X_train,X_val,X_test,y_train,y_val,y_test = pickle.load(f)"],"metadata":{"id":"6yDTX1mepNDc","executionInfo":{"status":"ok","timestamp":1718819910490,"user_tz":-120,"elapsed":1869,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["**Bektorizazioa**"],"metadata":{"id":"yy1EELOlqaKP"}},{"cell_type":"code","source":["print(type(X_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivy_VE0U5Y7p","executionInfo":{"status":"ok","timestamp":1718819910490,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}},"outputId":"1653f9e9-828e-4b38-8d07-6d168540dd4e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n"]}]},{"cell_type":"code","source":["def indize_hiztegia(X,n=1000):\n","\n","  h = {} # Hiztegi hutsa\n","\n","  for text in X: # X-ko hitz guztiak hiztegiko gakoak izango dira eta balio bezala hitz bakoitzari dagokion agerpen kopurua.\n","    for word in text.split():\n","      h [word] = h.get (word, 0) + 1\n","\n","  z = sorted(h.items(), key=lambda item: item[1],reverse= True) # Zerrenda bat da, hitza eta haren agerpenaren tuplak osatzen dutenak. Gainera, agerpen kopuru handienetik txikienera ordenatuta dago.\n","\n","  return {g:i for i,(g,b) in enumerate(z[:n])} # Funtzio honek beste hiztegi bat bueltatuko du non zerrendako hitzak gakoak diren eta balioa hitzaren posizioa zerendan. Hitz kopurua mugatzeko n balioa erabiltzen da.\n"],"metadata":{"id":"KtgjFcEx_ZYd","executionInfo":{"status":"ok","timestamp":1718819910491,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Ikus dezagun zeintzuk diren 'train' datuekin lortzen dugun lehenego 10 hitzetako indize hiztegia.\n","#word2index = indize_hiztegia(X_train,10)\n","#word2index"],"metadata":{"id":"CbkWaAermV5Q","executionInfo":{"status":"ok","timestamp":1718819912613,"user_tz":-120,"elapsed":265,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Gure entrenamenduko datuetan dauden hitz desberdin guztien kopurua kalkulatuko dugu, hau da, gure 'bokabularioa'.\n","voc = {w for txt in X_train for w in txt.split()}\n","len(voc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uryqH-Erppri","executionInfo":{"status":"ok","timestamp":1718819916899,"user_tz":-120,"elapsed":1824,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}},"outputId":"893d2fbf-c56d-40c9-9bb7-40663f7b2153"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["148468"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["word2index = indize_hiztegia(X_train,len(voc))"],"metadata":{"id":"hx5BSvpGOb8v","executionInfo":{"status":"ok","timestamp":1718819921255,"user_tz":-120,"elapsed":2705,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Gure datu multzoa nahiko handia denez, memoria arazoak izan ditzakegu datuak bektorizatzerakoan. Ondorioz, matrize dispertsoak erabili ditugu, hauek zero ez diren elementuak bakarrik gordetzen dituzte, memoriaren erabilera optimizatuz eta zero asko dituzten datu-multzo handietan eragiketa azkarragoak egiteko aukera ematen dute."],"metadata":{"id":"1o4h_pfC3Bu-"}},{"cell_type":"code","source":["from scipy.sparse import lil_matrix #lil_matrix motako matrizeak erabiliko ditugu memoriagatik\n","\n","def vectorize(X,hizt):\n","\n","  n = len(X) # Matrizearen errenkada kopurua.\n","  m = len(hizt) + 1 # Matrizearen zutabe kopurua (+ 1 'out off vocabulary' adierazten du.)\n","\n","  M = lil_matrix((n,m),dtype=np.int64) # SciPy motako n x m -ko M matrizea sortzen da.\n","\n","  for i,text in enumerate(X): # M agerpen matrizea da, X-ko eta hiztegiko hitzez sortua.\n","    for word in text.split():\n","      M[i,hizt.get(word,-1)] += 1\n","\n","  return M.tocsr() # Compressed Sparse Row array. Matrize hau egokiagoa da eredu aljebraikoekin lan egiteko."],"metadata":{"id":"4MDPPsfmNjZ8","executionInfo":{"status":"ok","timestamp":1718819921255,"user_tz":-120,"elapsed":4,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Mezuak bektorizatuko ditugu.\n","\n","X_train = vectorize(X_train, word2index)\n","X_val = vectorize(X_val, word2index)\n","X_test = vectorize(X_test, word2index)\n","\n","# Haien tamaina ikusiko dugu.\n","#print(X_train.shape,X_val.shape,X_test.shape)\n","\n","#Matrizearen azken zutabean dauden elementu guztien batura kalkulatuko dugu.\n","#print(X_train[:,-1].sum() , X_val[:,-1].sum() , X_test[:,-1].sum())"],"metadata":{"id":"cc6y6u4pSTFr","executionInfo":{"status":"ok","timestamp":1718819977122,"user_tz":-120,"elapsed":54044,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(type(X_train))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75S0OQNoTXW_","executionInfo":{"status":"ok","timestamp":1718819977122,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}},"outputId":"99a5af01-0565-4a30-ccbb-f254f157094a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'scipy.sparse._csr.csr_matrix'>\n"]}]},{"cell_type":"code","source":["# Etiketak bektorizatuko ditugu. Nahikoa da NumPy-ko 'array' bihutzea.\n","\n","y_train = np.asarray(y_train)\n","y_val = np.asarray(y_val)\n","y_test = np.asarray(y_test)"],"metadata":{"id":"BWKce_wuiG1e","executionInfo":{"status":"ok","timestamp":1718819977123,"user_tz":-120,"elapsed":5,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["**Google driven gorde**"],"metadata":{"id":"RIbNYB5I8C2j"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"iUiVBCxC8C2k","executionInfo":{"status":"ok","timestamp":1718819980522,"user_tz":-120,"elapsed":3404,"user":{"displayName":"Ane Acha","userId":"12550664087924387804"}}},"outputs":[],"source":["import pickle # Bektorizatutako datuak gordeko ditugu, fitxategi berri batean.\n","\n","with open(dir + \"vdata.bin\", \"wb\") as f:\n","  pickle.dump((X_train,X_val,X_test,y_train,y_val,y_test),f)"]}]}